{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Album</th>\n",
       "      <th>Song</th>\n",
       "      <th>Lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Monarchy of Roses</td>\n",
       "      <td>The crimson tide is flowing through your finge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Factory of Faith</td>\n",
       "      <td>All my life I was swinging for the fence,\\nI w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Brendan's Death Song</td>\n",
       "      <td>If I die before I get it done\\nWill you decide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Ethiopa</td>\n",
       "      <td>We're rolling everybody, it starts with bass\"\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Annie Wants A Baby</td>\n",
       "      <td>Lucy Rebar, she's a friend of mine\\nLater she'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Look Around</td>\n",
       "      <td>Stiff club, it's my nature,\\nCustom love is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>The Adventures of Raindance Maggie</td>\n",
       "      <td>Lipstick junkie\\nDebunked the all in one\\nShe ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Did I Let You Know</td>\n",
       "      <td>m comin' for you 'cause I adore you and\\nI'd l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Goodbye Hooray</td>\n",
       "      <td>Wooh, wooh, ha\\nJunior paints that old cafe\\nH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I'm With You</td>\n",
       "      <td>Happiness Loves Company</td>\n",
       "      <td>Stop marching 'cause you think you shot to num...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Album                                Song  \\\n",
       "0  I'm With You                   Monarchy of Roses   \n",
       "1  I'm With You                    Factory of Faith   \n",
       "2  I'm With You                Brendan's Death Song   \n",
       "3  I'm With You                             Ethiopa   \n",
       "4  I'm With You                  Annie Wants A Baby   \n",
       "5  I'm With You                         Look Around   \n",
       "6  I'm With You  The Adventures of Raindance Maggie   \n",
       "7  I'm With You                  Did I Let You Know   \n",
       "8  I'm With You                      Goodbye Hooray   \n",
       "9  I'm With You             Happiness Loves Company   \n",
       "\n",
       "                                              Lyrics  \n",
       "0  The crimson tide is flowing through your finge...  \n",
       "1  All my life I was swinging for the fence,\\nI w...  \n",
       "2  If I die before I get it done\\nWill you decide...  \n",
       "3  We're rolling everybody, it starts with bass\"\\...  \n",
       "4  Lucy Rebar, she's a friend of mine\\nLater she'...  \n",
       "5  Stiff club, it's my nature,\\nCustom love is th...  \n",
       "6  Lipstick junkie\\nDebunked the all in one\\nShe ...  \n",
       "7  m comin' for you 'cause I adore you and\\nI'd l...  \n",
       "8  Wooh, wooh, ha\\nJunior paints that old cafe\\nH...  \n",
       "9  Stop marching 'cause you think you shot to num...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rhcp_songs = pd.read_excel('rhcp_songs.xlsx')\n",
    "rhcp_songs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text = rhcp_songs['Lyrics'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text = \"\"\n",
    "for i in range(len(rhcp_songs)):\n",
    "    all_text = all_text + rhcp_songs['Lyrics'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = all_text.lower()\n",
    "chars = sorted(list(set(all_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters:  98370\n",
      "Total Vocab:  47\n"
     ]
    }
   ],
   "source": [
    "n_chars = len(all_text)\n",
    "n_vocab = len(chars)\n",
    "print(\"Total Characters: \", n_chars)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total patterns 91270\n"
     ]
    }
   ],
   "source": [
    "seq_length = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for n in range(len(rhcp_songs)):\n",
    "    raw_text = rhcp_songs['Lyrics'].iloc[n].lower()\n",
    "    n_chars = len(raw_text)\n",
    "    for i in range(0, n_chars - seq_length, 1):\n",
    "        seq_in = raw_text[i:i + seq_length]\n",
    "        seq_out = raw_text[i + seq_length]\n",
    "        dataX.append([char_to_int[char] for char in seq_in])\n",
    "        dataY.append(char_to_int[seq_out])\n",
    "n_patterns = len(dataX)\n",
    "print('Number of total patterns', n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "X = X / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y = to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From //anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1192: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From //anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:1299: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = EarlyStopping(monitor='loss',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='auto')\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "91270/91270 [==============================] - 919s - loss: 2.8928 - acc: 0.1936   \n",
      "Epoch 2/20\n",
      "91270/91270 [==============================] - 1349s - loss: 2.6637 - acc: 0.2300  \n",
      "Epoch 3/20\n",
      "91270/91270 [==============================] - 981s - loss: 2.5231 - acc: 0.2672   \n",
      "Epoch 4/20\n",
      "91270/91270 [==============================] - 1027s - loss: 2.3731 - acc: 0.3115  \n",
      "Epoch 5/20\n",
      "91270/91270 [==============================] - 1178s - loss: 2.2356 - acc: 0.3479  \n",
      "Epoch 6/20\n",
      "91270/91270 [==============================] - 2236s - loss: 2.1220 - acc: 0.3791  \n",
      "Epoch 7/20\n",
      "91270/91270 [==============================] - 1089s - loss: 2.0207 - acc: 0.4082  \n",
      "Epoch 8/20\n",
      "91270/91270 [==============================] - 1041s - loss: 1.9334 - acc: 0.4355  \n",
      "Epoch 9/20\n",
      "91270/91270 [==============================] - 975s - loss: 1.8522 - acc: 0.4573   \n",
      "Epoch 10/20\n",
      "91270/91270 [==============================] - 1772s - loss: 1.7820 - acc: 0.4764  \n",
      "Epoch 11/20\n",
      "59008/91270 [==================>...........] - ETA: 1840s - loss: 1.7129 - acc: 0.4955"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, epochs=5, batch_size=128, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" toldyoui'ddoitallagainthisisto \"\n",
      "2243\n",
      "to\n",
      "2243\n",
      "to\n",
      "2243\n",
      "to\n",
      "2243\n",
      "to\n",
      "2243\n",
      "to\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1042\n",
      "i\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "1199\n",
      "let's\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_word[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(100):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    print(index)\n",
    "    result = int_to_word[index]\n",
    "    seq_in = [int_to_word[value] for value in pattern]\n",
    "    print(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
